{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm","authorship_tag":"ABX9TyM9mCckS7JDiz5AvEgvFpy/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6f4ec4c5e5514329878286e90e48710b":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_acaec8f3910c4b7b9163e9377c463488","IPY_MODEL_2bcba24310eb4378a4b7aae3366b4e28"],"layout":"IPY_MODEL_0f9dc8f05f654b2695194fd0fdc13d0f"}},"acaec8f3910c4b7b9163e9377c463488":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"slice_index","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_bf100ba9b1d843c6bf1ce326de14492c","max":4,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_5259c502c54b49f285bdf9fd1182f749","value":4}},"2bcba24310eb4378a4b7aae3366b4e28":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_97f5647110f14618a3f595ff2cb886de","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}]}},"0f9dc8f05f654b2695194fd0fdc13d0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf100ba9b1d843c6bf1ce326de14492c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5259c502c54b49f285bdf9fd1182f749":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"97f5647110f14618a3f595ff2cb886de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9949e54c81e415f80a80c784a17feee":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_2889c08ac68243e58db37f77e48a4d75","IPY_MODEL_234717007cb6426f8cd9527d424cc819"],"layout":"IPY_MODEL_42dbc7c422af4939b3783acc3d07e501"}},"2889c08ac68243e58db37f77e48a4d75":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"slice_index","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_4bb93d8b3236452aa4977ac0c0e3554e","max":4,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_e864054b545f40cba816362b45786271","value":0}},"234717007cb6426f8cd9527d424cc819":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_7b5924eef82d42288e6c45ad20b16681","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}]}},"42dbc7c422af4939b3783acc3d07e501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bb93d8b3236452aa4977ac0c0e3554e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e864054b545f40cba816362b45786271":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"7b5924eef82d42288e6c45ad20b16681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUEwCgCYI-69","executionInfo":{"status":"ok","timestamp":1719056742204,"user_tz":-330,"elapsed":50182,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"0111c103-8a2f-4cf1-9d8e-4a5b25cb6c5d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iltUUCykCEGu","executionInfo":{"status":"ok","timestamp":1719056851047,"user_tz":-330,"elapsed":82580,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"52dc828f-df94-47c8-d6ac-af218e393e16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nnunetv2\n","  Downloading nnunetv2-2.4.2.tar.gz (184 kB)\n","\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/184.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174.1/184.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m184.1/184.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.3.0+cu121)\n","Collecting acvl-utils<0.3,>=0.2 (from nnunetv2)\n","  Downloading acvl_utils-0.2.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2)\n","  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (4.66.4)\n","Collecting dicom2nifti (from nnunetv2)\n","  Downloading dicom2nifti-2.4.11-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.11.4)\n","Collecting batchgenerators>=0.25 (from nnunetv2)\n","  Downloading batchgenerators-0.25.tar.gz (61 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.2.2)\n","Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.19.3)\n","Collecting SimpleITK>=2.2.1 (from nnunetv2)\n","  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.0.3)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.20.3)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2024.5.22)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.31.0)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (4.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (3.7.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.13.1)\n","Collecting imagecodecs (from nnunetv2)\n","  Downloading imagecodecs-2024.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.5 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m39.5/39.5 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yacs (from nnunetv2)\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting connected-components-3d (from acvl-utils<0.3,>=0.2->nnunetv2)\n","  Downloading connected_components_3d-3.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (9.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (0.18.3)\n","Collecting unittest2 (from batchgenerators>=0.25->nnunetv2)\n","  Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (3.5.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.3)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.31.6)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (1.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (1.12.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.2->nnunetv2)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2)\n","  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-gdcm (from dicom2nifti->nnunetv2)\n","  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (2.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunetv2) (67.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (2024.6.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2) (1.4.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2) (6.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.2->nnunetv2) (1.3.0)\n","Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Collecting traceback2 (from unittest2->batchgenerators>=0.25->nnunetv2)\n","  Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2)\n","  Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, dynamic-network-architectures\n","  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nnunetv2: filename=nnunetv2-2.4.2-py3-none-any.whl size=248753 sha256=7bc6973403ca09f9eedb1366f1cdbd447e316dddd1590fd6aa2e3263581b2b65\n","  Stored in directory: /root/.cache/pip/wheels/a8/24/6a/632a19c700123ed30f3f6380d84ea3f9e1d068bf5db817e804\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22439 sha256=91297e4875e7adcbf1d857f8576929cf4485e280cdbd0fc7a44cf7de811b0d30\n","  Stored in directory: /root/.cache/pip/wheels/ad/f0/84/52e8897591e66339bd2796681b9540b6c5e453c1461fa92a9e\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=89007 sha256=0cc5602a600732fa5f166e0e6c4b8f1394bf411d5961e630627ab88deceb629c\n","  Stored in directory: /root/.cache/pip/wheels/9e/b0/1b/40912fb58eb167b86cbc444ddb2e6ba382b248215295f932e2\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30049 sha256=b7568cd0749988a51e17a60e70018375adf1104bb7ceb4089e4db9854d47cd56\n","  Stored in directory: /root/.cache/pip/wheels/55/1b/13/a6419c8dbf998b9343710355ec3edc5c8e24d9b7b22eec95fb\n","Successfully built nnunetv2 acvl-utils batchgenerators dynamic-network-architectures\n","Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, imagecodecs, connected-components-3d, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dicom2nifti, nvidia-cusolver-cu12, batchgenerators, dynamic-network-architectures, acvl-utils, nnunetv2\n","Successfully installed SimpleITK-2.3.1 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 connected-components-3d-3.16.1 dicom2nifti-2.4.11 dynamic-network-architectures-0.3.1 imagecodecs-2024.6.1 linecache2-1.0.0 nnunetv2-2.4.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pydicom-2.4.4 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"4881f69d6eb64eb69d9354e77e98e6a1"}},"metadata":{}}],"source":["!pip install nnunetv2"]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrlKM70ixoWW","executionInfo":{"status":"ok","timestamp":1719056984378,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"87eab97d-fb44-4e4e-e001-5b908eac67a3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["nnUNetv2_train: /usr/local/bin/nnUNetv2_train\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Set nnUNet environment variables\n","os.environ['nnUNet_raw'] = '/content/drive/MyDrive/newData/nnUNet_raw'\n","os.environ['nnUNet_preprocessed'] = '/content/drive/MyDrive/newData/nnUNet_preprocessed'\n","os.environ['nnUNet_results'] = '/content/drive/MyDrive/newData/nnUNet_results'\n"],"metadata":{"id":"--6GWRmAF9sO","executionInfo":{"status":"ok","timestamp":1719057082991,"user_tz":-330,"elapsed":683,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!nnUNetv2_plan_and_preprocess -d 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AD3WLX5Eg3X","executionInfo":{"status":"ok","timestamp":1719057349551,"user_tz":-330,"elapsed":71936,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"dde22385-40c1-4fc6-dc9f-5bc6b918df84"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Fingerprint extraction...\n","Dataset001_FCDSegmentation3D\n","Experiment planning...\n","\n","############################\n","INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [  5. 255. 160.], 3d_lowres: [5, 255, 160]\n","2D U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 21, 'patch_size': (256, 160), 'median_image_size_in_voxels': array([255., 160.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n","\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n","3D fullres U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': (5, 256, 160), 'median_image_size_in_voxels': array([  5., 255., 160.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (1, 2, 2), (1, 2, 2), (1, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n","\n","Plans were saved to /content/drive/MyDrive/newData/nnUNet_preprocessed/Dataset001_FCDSegmentation3D/nnUNetPlans.json\n","Preprocessing...\n","Preprocessing dataset Dataset001_FCDSegmentation3D\n","Configuration: 2d...\n","100% 83/83 [00:42<00:00,  1.94it/s]\n","Configuration: 3d_fullres...\n","100% 83/83 [00:09<00:00,  8.62it/s]\n","Configuration: 3d_lowres...\n","INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset001_FCDSegmentation3D. Skipping.\n"]}]},{"cell_type":"code","source":["!nnUNetv2_train 3 3d_fullres 0 -tr nnUNetTrainer_100epochs --c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwIlpYrR6zBD","executionInfo":{"status":"ok","timestamp":1718174582325,"user_tz":-330,"elapsed":3153431,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"1e4f11c4-a983-4e95-cdf7-cc5ab05941f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Using device: cuda:0\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2024-06-12 05:50:34.076440: Using torch.compile...\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","2024-06-12 05:50:41.869429: do_dummy_2d_data_aug: False\n","2024-06-12 05:50:41.876996: Using splits from existing split file: /content/drive/MyDrive/newData/nnUNet_preprocessed/Dataset003_TrainingSplit/splits_final.json\n","2024-06-12 05:50:42.538942: The split file contains 5 splits.\n","2024-06-12 05:50:42.541779: Desired fold for training: 0\n","2024-06-12 05:50:42.543833: This split has 52 training and 14 validation cases.\n","using pin_memory on device 0\n","using pin_memory on device 0\n","\n","This is the configuration used by this training:\n","Configuration name: 3d_fullres\n"," {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [160, 5, 256], 'median_image_size_in_voxels': [160.0, 5.0, 255.0], 'spacing': [1.0000001788139343, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 1, 2], [2, 1, 2], [2, 1, 2], [2, 1, 2], [2, 1, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n","\n","These are the global plan.json settings:\n"," {'dataset_name': 'Dataset003_TrainingSplit', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0000001788139343, 1.0, 1.0], 'original_median_shape_after_transp': [160, 5, 255], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 610.9953002929688, 'mean': 133.9646453857422, 'median': 120.00137329101562, 'min': 0.0, 'percentile_00_5': 41.00022888183594, 'percentile_99_5': 404.99383544921875, 'std': 60.48310852050781}}} \n","\n","2024-06-12 05:50:44.883965: unpacking dataset...\n","2024-06-12 05:50:55.319070: unpacking done...\n","2024-06-12 05:50:57.501309: Unable to plot network architecture: nnUNet_compile is enabled!\n","2024-06-12 05:50:58.097971: \n","2024-06-12 05:50:58.101294: Epoch 50\n","2024-06-12 05:50:58.104799: Current learning rate: 0.00536\n","2024-06-12 05:53:01.789385: train_loss -0.6846\n","2024-06-12 05:53:01.798773: val_loss -0.2705\n","2024-06-12 05:53:01.809442: Pseudo dice [0.4869]\n","2024-06-12 05:53:01.833411: Epoch time: 123.69 s\n","2024-06-12 05:53:01.841155: Yayy! New best EMA pseudo Dice: 0.4283\n","2024-06-12 05:53:16.667787: \n","2024-06-12 05:53:16.670624: Epoch 51\n","2024-06-12 05:53:16.672647: Current learning rate: 0.00526\n","2024-06-12 05:54:11.789103: train_loss -0.7025\n","2024-06-12 05:54:11.803530: val_loss -0.2987\n","2024-06-12 05:54:11.820062: Pseudo dice [0.4118]\n","2024-06-12 05:54:11.837222: Epoch time: 55.12 s\n","2024-06-12 05:54:13.811194: \n","2024-06-12 05:54:13.814195: Epoch 52\n","2024-06-12 05:54:13.817103: Current learning rate: 0.00517\n","2024-06-12 05:55:12.037025: train_loss -0.7\n","2024-06-12 05:55:12.048683: val_loss -0.3175\n","2024-06-12 05:55:12.056159: Pseudo dice [0.4694]\n","2024-06-12 05:55:12.062884: Epoch time: 58.23 s\n","2024-06-12 05:55:12.070040: Yayy! New best EMA pseudo Dice: 0.4309\n","2024-06-12 05:55:14.733478: \n","2024-06-12 05:55:14.736703: Epoch 53\n","2024-06-12 05:55:14.739820: Current learning rate: 0.00507\n","2024-06-12 05:56:13.324616: train_loss -0.6937\n","2024-06-12 05:56:13.343795: val_loss -0.2895\n","2024-06-12 05:56:13.362852: Pseudo dice [0.4691]\n","2024-06-12 05:56:13.378339: Epoch time: 58.59 s\n","2024-06-12 05:56:13.396519: Yayy! New best EMA pseudo Dice: 0.4348\n","2024-06-12 05:56:16.525734: \n","2024-06-12 05:56:16.528746: Epoch 54\n","2024-06-12 05:56:16.530997: Current learning rate: 0.00497\n","2024-06-12 05:57:15.630481: train_loss -0.7222\n","2024-06-12 05:57:15.646580: val_loss -0.309\n","2024-06-12 05:57:15.659092: Pseudo dice [0.4676]\n","2024-06-12 05:57:15.669041: Epoch time: 59.11 s\n","2024-06-12 05:57:15.681421: Yayy! New best EMA pseudo Dice: 0.438\n","2024-06-12 05:57:18.441164: \n","2024-06-12 05:57:18.444101: Epoch 55\n","2024-06-12 05:57:18.447059: Current learning rate: 0.00487\n","2024-06-12 05:58:15.934485: train_loss -0.7064\n","2024-06-12 05:58:15.955457: val_loss -0.3037\n","2024-06-12 05:58:15.968426: Pseudo dice [0.4141]\n","2024-06-12 05:58:16.000053: Epoch time: 57.49 s\n","2024-06-12 05:58:18.193534: \n","2024-06-12 05:58:18.196611: Epoch 56\n","2024-06-12 05:58:18.199504: Current learning rate: 0.00478\n","2024-06-12 05:59:17.410051: train_loss -0.7066\n","2024-06-12 05:59:17.427242: val_loss -0.3138\n","2024-06-12 05:59:17.435186: Pseudo dice [0.4683]\n","2024-06-12 05:59:17.459803: Epoch time: 59.22 s\n","2024-06-12 05:59:17.475092: Yayy! New best EMA pseudo Dice: 0.4389\n","2024-06-12 05:59:20.194680: \n","2024-06-12 05:59:20.197616: Epoch 57\n","2024-06-12 05:59:20.201047: Current learning rate: 0.00468\n","2024-06-12 06:00:17.991479: train_loss -0.7012\n","2024-06-12 06:00:18.001926: val_loss -0.3437\n","2024-06-12 06:00:18.017443: Pseudo dice [0.4869]\n","2024-06-12 06:00:18.030468: Epoch time: 57.8 s\n","2024-06-12 06:00:18.040516: Yayy! New best EMA pseudo Dice: 0.4437\n","2024-06-12 06:00:20.871969: \n","2024-06-12 06:00:20.875741: Epoch 58\n","2024-06-12 06:00:20.878747: Current learning rate: 0.00458\n","2024-06-12 06:01:20.782993: train_loss -0.719\n","2024-06-12 06:01:20.823158: val_loss -0.2669\n","2024-06-12 06:01:20.856725: Pseudo dice [0.4184]\n","2024-06-12 06:01:20.876528: Epoch time: 59.91 s\n","2024-06-12 06:01:22.909076: \n","2024-06-12 06:01:22.912589: Epoch 59\n","2024-06-12 06:01:22.916385: Current learning rate: 0.00448\n","2024-06-12 06:02:21.377599: train_loss -0.716\n","2024-06-12 06:02:21.389385: val_loss -0.2645\n","2024-06-12 06:02:21.408775: Pseudo dice [0.4261]\n","2024-06-12 06:02:21.457595: Epoch time: 58.47 s\n","2024-06-12 06:02:23.295904: \n","2024-06-12 06:02:23.298873: Epoch 60\n","2024-06-12 06:02:23.302051: Current learning rate: 0.00438\n","2024-06-12 06:03:20.367590: train_loss -0.7105\n","2024-06-12 06:03:20.387660: val_loss -0.3737\n","2024-06-12 06:03:20.421179: Pseudo dice [0.5071]\n","2024-06-12 06:03:20.453160: Epoch time: 57.07 s\n","2024-06-12 06:03:20.478459: Yayy! New best EMA pseudo Dice: 0.4464\n","2024-06-12 06:03:23.545969: \n","2024-06-12 06:03:23.548838: Epoch 61\n","2024-06-12 06:03:23.550962: Current learning rate: 0.00429\n","2024-06-12 06:04:21.557799: train_loss -0.6873\n","2024-06-12 06:04:21.589043: val_loss -0.3551\n","2024-06-12 06:04:21.599952: Pseudo dice [0.4983]\n","2024-06-12 06:04:21.636718: Epoch time: 58.01 s\n","2024-06-12 06:04:21.645645: Yayy! New best EMA pseudo Dice: 0.4516\n","2024-06-12 06:04:24.316828: \n","2024-06-12 06:04:24.320148: Epoch 62\n","2024-06-12 06:04:24.323273: Current learning rate: 0.00419\n","2024-06-12 06:05:24.287269: train_loss -0.6956\n","2024-06-12 06:05:24.304381: val_loss -0.265\n","2024-06-12 06:05:24.319925: Pseudo dice [0.3818]\n","2024-06-12 06:05:24.332480: Epoch time: 59.97 s\n","2024-06-12 06:05:26.270455: \n","2024-06-12 06:05:26.273660: Epoch 63\n","2024-06-12 06:05:26.275639: Current learning rate: 0.00409\n","2024-06-12 06:06:22.774842: train_loss -0.7182\n","2024-06-12 06:06:22.788503: val_loss -0.2556\n","2024-06-12 06:06:22.803160: Pseudo dice [0.4008]\n","2024-06-12 06:06:22.812598: Epoch time: 56.51 s\n","2024-06-12 06:06:24.637826: \n","2024-06-12 06:06:24.640713: Epoch 64\n","2024-06-12 06:06:24.643582: Current learning rate: 0.00399\n","2024-06-12 06:07:22.897593: train_loss -0.6931\n","2024-06-12 06:07:22.920962: val_loss -0.2354\n","2024-06-12 06:07:22.955011: Pseudo dice [0.3537]\n","2024-06-12 06:07:22.970679: Epoch time: 58.26 s\n","2024-06-12 06:07:24.724933: \n","2024-06-12 06:07:24.728373: Epoch 65\n","2024-06-12 06:07:24.731921: Current learning rate: 0.00389\n","2024-06-12 06:08:23.279981: train_loss -0.7167\n","2024-06-12 06:08:23.291386: val_loss -0.2521\n","2024-06-12 06:08:23.303470: Pseudo dice [0.388]\n","2024-06-12 06:08:23.312845: Epoch time: 58.56 s\n","2024-06-12 06:08:25.003996: \n","2024-06-12 06:08:25.023232: Epoch 66\n","2024-06-12 06:08:25.026844: Current learning rate: 0.00379\n","2024-06-12 06:09:26.518589: train_loss -0.7209\n","2024-06-12 06:09:26.535795: val_loss -0.2641\n","2024-06-12 06:09:26.547863: Pseudo dice [0.4189]\n","2024-06-12 06:09:26.558062: Epoch time: 61.52 s\n","2024-06-12 06:09:28.978527: \n","2024-06-12 06:09:28.981295: Epoch 67\n","2024-06-12 06:09:28.984335: Current learning rate: 0.00369\n","2024-06-12 06:10:23.316984: train_loss -0.7192\n","2024-06-12 06:10:23.330199: val_loss -0.3598\n","2024-06-12 06:10:23.343158: Pseudo dice [0.488]\n","2024-06-12 06:10:23.353180: Epoch time: 54.34 s\n","2024-06-12 06:10:25.097785: \n","2024-06-12 06:10:25.100796: Epoch 68\n","2024-06-12 06:10:25.103028: Current learning rate: 0.00359\n","2024-06-12 06:11:22.109494: train_loss -0.7412\n","2024-06-12 06:11:22.131018: val_loss -0.2601\n","2024-06-12 06:11:22.143636: Pseudo dice [0.3906]\n","2024-06-12 06:11:22.159372: Epoch time: 57.01 s\n","2024-06-12 06:11:24.085378: \n","2024-06-12 06:11:24.089607: Epoch 69\n","2024-06-12 06:11:24.092190: Current learning rate: 0.00349\n","2024-06-12 06:12:22.827211: train_loss -0.7404\n","2024-06-12 06:12:22.840557: val_loss -0.3145\n","2024-06-12 06:12:22.847269: Pseudo dice [0.4499]\n","2024-06-12 06:12:22.853591: Epoch time: 58.74 s\n","2024-06-12 06:12:24.634149: \n","2024-06-12 06:12:24.636987: Epoch 70\n","2024-06-12 06:12:24.639031: Current learning rate: 0.00338\n","2024-06-12 06:13:25.426876: train_loss -0.7332\n","2024-06-12 06:13:25.447591: val_loss -0.3074\n","2024-06-12 06:13:25.461444: Pseudo dice [0.458]\n","2024-06-12 06:13:25.488222: Epoch time: 60.79 s\n","2024-06-12 06:13:27.380044: \n","2024-06-12 06:13:27.383712: Epoch 71\n","2024-06-12 06:13:27.386840: Current learning rate: 0.00328\n","2024-06-12 06:14:25.134701: train_loss -0.7213\n","2024-06-12 06:14:25.147959: val_loss -0.3267\n","2024-06-12 06:14:25.164106: Pseudo dice [0.4792]\n","2024-06-12 06:14:25.176728: Epoch time: 57.76 s\n","2024-06-12 06:14:26.949384: \n","2024-06-12 06:14:26.952898: Epoch 72\n","2024-06-12 06:14:26.955328: Current learning rate: 0.00318\n","2024-06-12 06:15:25.215556: train_loss -0.7207\n","2024-06-12 06:15:25.224684: val_loss -0.3506\n","2024-06-12 06:15:25.249964: Pseudo dice [0.5145]\n","2024-06-12 06:15:25.258312: Epoch time: 58.27 s\n","2024-06-12 06:15:27.051946: \n","2024-06-12 06:15:27.055028: Epoch 73\n","2024-06-12 06:15:27.057096: Current learning rate: 0.00308\n","2024-06-12 06:16:27.479785: train_loss -0.7198\n","2024-06-12 06:16:27.507428: val_loss -0.2539\n","2024-06-12 06:16:27.528323: Pseudo dice [0.4105]\n","2024-06-12 06:16:27.548277: Epoch time: 60.43 s\n","2024-06-12 06:16:29.540962: \n","2024-06-12 06:16:29.543992: Epoch 74\n","2024-06-12 06:16:29.546298: Current learning rate: 0.00297\n","2024-06-12 06:17:27.509101: train_loss -0.7186\n","2024-06-12 06:17:27.538183: val_loss -0.2915\n","2024-06-12 06:17:27.547168: Pseudo dice [0.4488]\n","2024-06-12 06:17:27.558145: Epoch time: 57.97 s\n","2024-06-12 06:17:29.285522: \n","2024-06-12 06:17:29.288773: Epoch 75\n","2024-06-12 06:17:29.290872: Current learning rate: 0.00287\n","2024-06-12 06:18:26.753732: train_loss -0.734\n","2024-06-12 06:18:26.766023: val_loss -0.307\n","2024-06-12 06:18:26.775516: Pseudo dice [0.4583]\n","2024-06-12 06:18:26.789600: Epoch time: 57.47 s\n","2024-06-12 06:18:28.772462: \n","2024-06-12 06:18:28.776031: Epoch 76\n","2024-06-12 06:18:28.778591: Current learning rate: 0.00277\n","2024-06-12 06:19:25.606525: train_loss -0.7357\n","2024-06-12 06:19:25.620108: val_loss -0.2569\n","2024-06-12 06:19:25.635373: Pseudo dice [0.4205]\n","2024-06-12 06:19:25.666008: Epoch time: 56.84 s\n","2024-06-12 06:19:27.443667: \n","2024-06-12 06:19:27.446705: Epoch 77\n","2024-06-12 06:19:27.448859: Current learning rate: 0.00266\n","2024-06-12 06:20:25.733948: train_loss -0.7269\n","2024-06-12 06:20:25.745573: val_loss -0.3463\n","2024-06-12 06:20:25.756356: Pseudo dice [0.4636]\n","2024-06-12 06:20:25.767505: Epoch time: 58.29 s\n","2024-06-12 06:20:28.097597: \n","2024-06-12 06:20:28.100885: Epoch 78\n","2024-06-12 06:20:28.118955: Current learning rate: 0.00256\n","2024-06-12 06:21:27.421826: train_loss -0.7185\n","2024-06-12 06:21:27.440527: val_loss -0.3129\n","2024-06-12 06:21:27.462398: Pseudo dice [0.4298]\n","2024-06-12 06:21:27.474698: Epoch time: 59.33 s\n","2024-06-12 06:21:29.385293: \n","2024-06-12 06:21:29.388729: Epoch 79\n","2024-06-12 06:21:29.391988: Current learning rate: 0.00245\n","2024-06-12 06:22:26.127776: train_loss -0.75\n","2024-06-12 06:22:26.165098: val_loss -0.3348\n","2024-06-12 06:22:26.182279: Pseudo dice [0.5151]\n","2024-06-12 06:22:26.197221: Epoch time: 56.74 s\n","2024-06-12 06:22:28.077022: \n","2024-06-12 06:22:28.082393: Epoch 80\n","2024-06-12 06:22:28.085641: Current learning rate: 0.00235\n","2024-06-12 06:23:24.977611: train_loss -0.7426\n","2024-06-12 06:23:24.990347: val_loss -0.2243\n","2024-06-12 06:23:25.004907: Pseudo dice [0.3675]\n","2024-06-12 06:23:25.018262: Epoch time: 56.9 s\n","2024-06-12 06:23:26.846504: \n","2024-06-12 06:23:26.849772: Epoch 81\n","2024-06-12 06:23:26.851846: Current learning rate: 0.00224\n","2024-06-12 06:24:24.436437: train_loss -0.7398\n","2024-06-12 06:24:24.449630: val_loss -0.2516\n","2024-06-12 06:24:24.463126: Pseudo dice [0.3762]\n","2024-06-12 06:24:24.471120: Epoch time: 57.59 s\n","2024-06-12 06:24:26.354035: \n","2024-06-12 06:24:26.357762: Epoch 82\n","2024-06-12 06:24:26.360549: Current learning rate: 0.00214\n","2024-06-12 06:25:25.684052: train_loss -0.7371\n","2024-06-12 06:25:25.701725: val_loss -0.3063\n","2024-06-12 06:25:25.719612: Pseudo dice [0.4554]\n","2024-06-12 06:25:25.730081: Epoch time: 59.33 s\n","2024-06-12 06:25:27.468982: \n","2024-06-12 06:25:27.472037: Epoch 83\n","2024-06-12 06:25:27.475483: Current learning rate: 0.00203\n","2024-06-12 06:26:25.610296: train_loss -0.7432\n","2024-06-12 06:26:25.639053: val_loss -0.2695\n","2024-06-12 06:26:25.675054: Pseudo dice [0.4195]\n","2024-06-12 06:26:25.695713: Epoch time: 58.14 s\n","2024-06-12 06:26:27.744294: \n","2024-06-12 06:26:27.747999: Epoch 84\n","2024-06-12 06:26:27.751477: Current learning rate: 0.00192\n","2024-06-12 06:27:25.750957: train_loss -0.7429\n","2024-06-12 06:27:25.772544: val_loss -0.3181\n","2024-06-12 06:27:25.806213: Pseudo dice [0.4786]\n","2024-06-12 06:27:25.818086: Epoch time: 58.01 s\n","2024-06-12 06:27:27.673527: \n","2024-06-12 06:27:27.676668: Epoch 85\n","2024-06-12 06:27:27.679865: Current learning rate: 0.00181\n","2024-06-12 06:28:24.336575: train_loss -0.7491\n","2024-06-12 06:28:24.353365: val_loss -0.3682\n","2024-06-12 06:28:24.369814: Pseudo dice [0.5042]\n","2024-06-12 06:28:24.383454: Epoch time: 56.66 s\n","2024-06-12 06:28:26.324078: \n","2024-06-12 06:28:26.327791: Epoch 86\n","2024-06-12 06:28:26.332037: Current learning rate: 0.0017\n","2024-06-12 06:29:25.330453: train_loss -0.7407\n","2024-06-12 06:29:25.341797: val_loss -0.3489\n","2024-06-12 06:29:25.353946: Pseudo dice [0.4814]\n","2024-06-12 06:29:25.369185: Epoch time: 59.01 s\n","2024-06-12 06:29:27.111390: \n","2024-06-12 06:29:27.114414: Epoch 87\n","2024-06-12 06:29:27.118508: Current learning rate: 0.00159\n","2024-06-12 06:30:27.760175: train_loss -0.7408\n","2024-06-12 06:30:27.797371: val_loss -0.3457\n","2024-06-12 06:30:27.832872: Pseudo dice [0.4987]\n","2024-06-12 06:30:27.842145: Epoch time: 60.65 s\n","2024-06-12 06:30:27.850449: Yayy! New best EMA pseudo Dice: 0.4546\n","2024-06-12 06:30:30.952619: \n","2024-06-12 06:30:30.955688: Epoch 88\n","2024-06-12 06:30:30.957903: Current learning rate: 0.00148\n","2024-06-12 06:31:28.646791: train_loss -0.7403\n","2024-06-12 06:31:28.674509: val_loss -0.3143\n","2024-06-12 06:31:28.698872: Pseudo dice [0.4559]\n","2024-06-12 06:31:28.717825: Epoch time: 57.7 s\n","2024-06-12 06:31:28.741123: Yayy! New best EMA pseudo Dice: 0.4547\n","2024-06-12 06:31:31.695658: \n","2024-06-12 06:31:31.698657: Epoch 89\n","2024-06-12 06:31:31.700756: Current learning rate: 0.00137\n","2024-06-12 06:32:28.343026: train_loss -0.7386\n","2024-06-12 06:32:28.364636: val_loss -0.3213\n","2024-06-12 06:32:28.385970: Pseudo dice [0.4785]\n","2024-06-12 06:32:28.401689: Epoch time: 56.65 s\n","2024-06-12 06:32:28.414287: Yayy! New best EMA pseudo Dice: 0.4571\n","2024-06-12 06:32:31.544022: \n","2024-06-12 06:32:31.546848: Epoch 90\n","2024-06-12 06:32:31.549684: Current learning rate: 0.00126\n","2024-06-12 06:33:31.169017: train_loss -0.7282\n","2024-06-12 06:33:31.187354: val_loss -0.2776\n","2024-06-12 06:33:31.202857: Pseudo dice [0.4227]\n","2024-06-12 06:33:31.228524: Epoch time: 59.63 s\n","2024-06-12 06:33:32.944203: \n","2024-06-12 06:33:32.947131: Epoch 91\n","2024-06-12 06:33:32.949034: Current learning rate: 0.00115\n","2024-06-12 06:34:35.558326: train_loss -0.7486\n","2024-06-12 06:34:35.596650: val_loss -0.2761\n","2024-06-12 06:34:35.638832: Pseudo dice [0.426]\n","2024-06-12 06:34:35.648695: Epoch time: 62.62 s\n","2024-06-12 06:34:37.693485: \n","2024-06-12 06:34:37.696597: Epoch 92\n","2024-06-12 06:34:37.699951: Current learning rate: 0.00103\n","2024-06-12 06:35:37.022641: train_loss -0.7406\n","2024-06-12 06:35:37.037794: val_loss -0.1853\n","2024-06-12 06:35:37.049966: Pseudo dice [0.3685]\n","2024-06-12 06:35:37.061653: Epoch time: 59.33 s\n","2024-06-12 06:35:38.764479: \n","2024-06-12 06:35:38.767794: Epoch 93\n","2024-06-12 06:35:38.770332: Current learning rate: 0.00091\n","2024-06-12 06:36:35.138123: train_loss -0.7633\n","2024-06-12 06:36:35.158828: val_loss -0.25\n","2024-06-12 06:36:35.167262: Pseudo dice [0.4192]\n","2024-06-12 06:36:35.176472: Epoch time: 56.37 s\n","2024-06-12 06:36:36.925797: \n","2024-06-12 06:36:36.929340: Epoch 94\n","2024-06-12 06:36:36.933186: Current learning rate: 0.00079\n","2024-06-12 06:37:33.001851: train_loss -0.7604\n","2024-06-12 06:37:33.010880: val_loss -0.2659\n","2024-06-12 06:37:33.017564: Pseudo dice [0.4239]\n","2024-06-12 06:37:33.024369: Epoch time: 56.08 s\n","2024-06-12 06:37:34.670981: \n","2024-06-12 06:37:34.674027: Epoch 95\n","2024-06-12 06:37:34.677138: Current learning rate: 0.00067\n","2024-06-12 06:38:32.089734: train_loss -0.7678\n","2024-06-12 06:38:32.105669: val_loss -0.3202\n","2024-06-12 06:38:32.122883: Pseudo dice [0.4625]\n","2024-06-12 06:38:32.140602: Epoch time: 57.42 s\n","2024-06-12 06:38:33.916388: \n","2024-06-12 06:38:33.919394: Epoch 96\n","2024-06-12 06:38:33.921690: Current learning rate: 0.00055\n","2024-06-12 06:39:32.391898: train_loss -0.7569\n","2024-06-12 06:39:32.408291: val_loss -0.2794\n","2024-06-12 06:39:32.440676: Pseudo dice [0.3984]\n","2024-06-12 06:39:32.455454: Epoch time: 58.48 s\n","2024-06-12 06:39:34.260954: \n","2024-06-12 06:39:34.264722: Epoch 97\n","2024-06-12 06:39:34.267449: Current learning rate: 0.00043\n","2024-06-12 06:40:30.904162: train_loss -0.7582\n","2024-06-12 06:40:30.927154: val_loss -0.2824\n","2024-06-12 06:40:30.946570: Pseudo dice [0.4386]\n","2024-06-12 06:40:30.967480: Epoch time: 56.64 s\n","2024-06-12 06:40:32.858084: \n","2024-06-12 06:40:32.862143: Epoch 98\n","2024-06-12 06:40:32.866613: Current learning rate: 0.0003\n","2024-06-12 06:41:30.889558: train_loss -0.7564\n","2024-06-12 06:41:30.897826: val_loss -0.2971\n","2024-06-12 06:41:30.907474: Pseudo dice [0.4367]\n","2024-06-12 06:41:30.919081: Epoch time: 58.03 s\n","2024-06-12 06:41:32.598617: \n","2024-06-12 06:41:32.613708: Epoch 99\n","2024-06-12 06:41:32.617414: Current learning rate: 0.00016\n","2024-06-12 06:42:31.885121: train_loss -0.7538\n","2024-06-12 06:42:31.903828: val_loss -0.2772\n","2024-06-12 06:42:31.916779: Pseudo dice [0.4244]\n","2024-06-12 06:42:31.931189: Epoch time: 59.29 s\n","2024-06-12 06:42:34.447725: Training done.\n","2024-06-12 06:42:34.532522: Using splits from existing split file: /content/drive/MyDrive/newData/nnUNet_preprocessed/Dataset003_TrainingSplit/splits_final.json\n","2024-06-12 06:42:34.541180: The split file contains 5 splits.\n","2024-06-12 06:42:34.545489: Desired fold for training: 0\n","2024-06-12 06:42:34.548898: This split has 52 training and 14 validation cases.\n","2024-06-12 06:42:34.552987: predicting case_0004\n","2024-06-12 06:42:34.573587: case_0004, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.005585: predicting case_0006\n","2024-06-12 06:42:49.023742: case_0006, shape torch.Size([1, 160, 5, 194]), rank 0\n","2024-06-12 06:42:49.091032: predicting case_0024\n","2024-06-12 06:42:49.109021: case_0024, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.177944: predicting case_0034\n","2024-06-12 06:42:49.201871: case_0034, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.286077: predicting case_0037\n","2024-06-12 06:42:49.316340: case_0037, shape torch.Size([1, 160, 5, 222]), rank 0\n","2024-06-12 06:42:49.382966: predicting case_0044\n","2024-06-12 06:42:49.397447: case_0044, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.464474: predicting case_0045\n","2024-06-12 06:42:49.491664: case_0045, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.569609: predicting case_0049\n","2024-06-12 06:42:49.602370: case_0049, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.668384: predicting case_0050\n","2024-06-12 06:42:49.685197: case_0050, shape torch.Size([1, 160, 5, 215]), rank 0\n","2024-06-12 06:42:49.754930: predicting case_0053\n","2024-06-12 06:42:49.792864: case_0053, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.860345: predicting case_0054\n","2024-06-12 06:42:49.905631: case_0054, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:49.970455: predicting case_0060\n","2024-06-12 06:42:50.007740: case_0060, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:50.075563: predicting case_0062\n","2024-06-12 06:42:50.112280: case_0062, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:50.177969: predicting case_0063\n","2024-06-12 06:42:50.228224: case_0063, shape torch.Size([1, 160, 5, 255]), rank 0\n","2024-06-12 06:42:58.469714: Validation complete\n","2024-06-12 06:42:58.472317: Mean Validation Dice:  0.3226820031620791\n"]}]},{"cell_type":"code","source":["# Loop through each fold from 0 to 4\n","for fold in range(5):\n","    # Construct the command\n","    command = f\"nnUNetv2_train 1 3d_fullres {fold} -tr nnUNetTrainerDAOrd0\"\n","\n","    # Print the command (optional, for verification)\n","    print(command)\n","\n","    # Execute the command\n","    !{command}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yabmbfAIoHy","outputId":"72558201-b690-48fa-e214-e9cbdd018c59","executionInfo":{"status":"ok","timestamp":1719057450609,"user_tz":-330,"elapsed":26480,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["nnUNetv2_train 1 3d_fullres 0 -tr nnUNetTrainerDAOrd0\n","nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n","nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n","nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 274, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 195, in run_training\n","    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 61, in get_trainer_from_args\n","    preprocessed_dataset_folder_base = join(nnUNet_preprocessed, maybe_convert_to_dataset_name(dataset_name_or_id))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 74, in maybe_convert_to_dataset_name\n","    return convert_id_to_dataset_name(dataset_name_or_id)\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n","    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n","RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n","nnUNet_preprocessed=None\n","nnUNet_results=None\n","nnUNet_raw=None\n","If something is not right, adapt your environment variables.\n","nnUNetv2_train 1 3d_fullres 1 -tr nnUNetTrainerDAOrd0\n","nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n","nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n","nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 274, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 195, in run_training\n","    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 61, in get_trainer_from_args\n","    preprocessed_dataset_folder_base = join(nnUNet_preprocessed, maybe_convert_to_dataset_name(dataset_name_or_id))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 74, in maybe_convert_to_dataset_name\n","    return convert_id_to_dataset_name(dataset_name_or_id)\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n","    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n","RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n","nnUNet_preprocessed=None\n","nnUNet_results=None\n","nnUNet_raw=None\n","If something is not right, adapt your environment variables.\n","nnUNetv2_train 1 3d_fullres 2 -tr nnUNetTrainerDAOrd0\n","nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n","nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n","nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 274, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 195, in run_training\n","    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 61, in get_trainer_from_args\n","    preprocessed_dataset_folder_base = join(nnUNet_preprocessed, maybe_convert_to_dataset_name(dataset_name_or_id))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 74, in maybe_convert_to_dataset_name\n","    return convert_id_to_dataset_name(dataset_name_or_id)\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n","    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n","RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n","nnUNet_preprocessed=None\n","nnUNet_results=None\n","nnUNet_raw=None\n","If something is not right, adapt your environment variables.\n","nnUNetv2_train 1 3d_fullres 3 -tr nnUNetTrainerDAOrd0\n","nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n","nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n","nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 274, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 195, in run_training\n","    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 61, in get_trainer_from_args\n","    preprocessed_dataset_folder_base = join(nnUNet_preprocessed, maybe_convert_to_dataset_name(dataset_name_or_id))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 74, in maybe_convert_to_dataset_name\n","    return convert_id_to_dataset_name(dataset_name_or_id)\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n","    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n","RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n","nnUNet_preprocessed=None\n","nnUNet_results=None\n","nnUNet_raw=None\n","If something is not right, adapt your environment variables.\n","nnUNetv2_train 1 3d_fullres 4 -tr nnUNetTrainerDAOrd0\n","nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n","nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n","nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 274, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 195, in run_training\n","    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 61, in get_trainer_from_args\n","    preprocessed_dataset_folder_base = join(nnUNet_preprocessed, maybe_convert_to_dataset_name(dataset_name_or_id))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 74, in maybe_convert_to_dataset_name\n","    return convert_id_to_dataset_name(dataset_name_or_id)\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n","    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n","RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n","nnUNet_preprocessed=None\n","nnUNet_results=None\n","nnUNet_raw=None\n","If something is not right, adapt your environment variables.\n"]}]},{"cell_type":"code","source":["!nnUNetv2_predict -i /content/drive/MyDrive/newData/nnUNet_raw/Dataset003_TrainingSplit/imagesTs  -o /content/drive/MyDrive/newData/nnUNet_raw/Dataset003_TrainingSplit/segmentationresults  -d 3 -c 3d_fullres -tr nnUNetTrainer_100epochs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xo-Xoaucv9Qb","executionInfo":{"status":"ok","timestamp":1718201026288,"user_tz":-330,"elapsed":34992,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"44e92e00-cf64-4ba7-e72a-47018c742f28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","There are 17 cases in the source folder\n","I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n","There are 17 cases that I would like to predict\n","\n","Predicting case_0000:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00,  1.26it/s]\n","100% 1/1 [00:00<00:00, 19.19it/s]\n","100% 1/1 [00:00<00:00, 18.99it/s]\n","100% 1/1 [00:00<00:00, 18.57it/s]\n","100% 1/1 [00:00<00:00, 16.02it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0000\n","\n","Predicting case_0001:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.72it/s]\n","100% 1/1 [00:00<00:00, 18.22it/s]\n","100% 1/1 [00:00<00:00, 18.55it/s]\n","100% 1/1 [00:00<00:00, 19.28it/s]\n","100% 1/1 [00:00<00:00, 18.85it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0001\n","\n","Predicting case_0002:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 19.39it/s]\n","100% 1/1 [00:00<00:00, 18.84it/s]\n","100% 1/1 [00:00<00:00, 18.52it/s]\n","100% 1/1 [00:00<00:00, 17.61it/s]\n","100% 1/1 [00:00<00:00, 18.64it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0002\n","\n","Predicting case_0003:\n","perform_everything_on_device: True\n","100% 20/20 [00:01<00:00, 17.31it/s]\n","100% 20/20 [00:01<00:00, 17.34it/s]\n","100% 20/20 [00:01<00:00, 16.72it/s]\n","100% 20/20 [00:01<00:00, 17.26it/s]\n","100% 20/20 [00:01<00:00, 17.30it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0003\n","\n","Predicting case_0004:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 16.53it/s]\n","100% 1/1 [00:00<00:00, 18.53it/s]\n","100% 1/1 [00:00<00:00, 18.92it/s]\n","100% 1/1 [00:00<00:00, 18.72it/s]\n","100% 1/1 [00:00<00:00, 19.27it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0004\n","\n","Predicting case_0005:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 17.98it/s]\n","100% 1/1 [00:00<00:00, 17.09it/s]\n","100% 1/1 [00:00<00:00, 18.61it/s]\n","100% 1/1 [00:00<00:00, 19.49it/s]\n","100% 1/1 [00:00<00:00, 17.44it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0005\n","\n","Predicting case_0006:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 15.67it/s]\n","100% 1/1 [00:00<00:00, 18.25it/s]\n","100% 1/1 [00:00<00:00, 18.62it/s]\n","100% 1/1 [00:00<00:00, 18.70it/s]\n","100% 1/1 [00:00<00:00, 18.64it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0006\n","\n","Predicting case_0007:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.84it/s]\n","100% 1/1 [00:00<00:00, 15.14it/s]\n","100% 1/1 [00:00<00:00, 17.04it/s]\n","100% 1/1 [00:00<00:00, 18.37it/s]\n","100% 1/1 [00:00<00:00, 17.74it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0007\n","\n","Predicting case_0008:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 14.60it/s]\n","100% 1/1 [00:00<00:00, 17.64it/s]\n","100% 1/1 [00:00<00:00, 15.97it/s]\n","100% 1/1 [00:00<00:00, 18.89it/s]\n","100% 1/1 [00:00<00:00, 18.85it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0008\n","\n","Predicting case_0009:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.45it/s]\n","100% 1/1 [00:00<00:00, 18.57it/s]\n","100% 1/1 [00:00<00:00, 18.86it/s]\n","100% 1/1 [00:00<00:00, 18.75it/s]\n","100% 1/1 [00:00<00:00, 19.02it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0009\n","\n","Predicting case_0010:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.62it/s]\n","100% 1/1 [00:00<00:00, 18.84it/s]\n","100% 1/1 [00:00<00:00, 19.24it/s]\n","100% 1/1 [00:00<00:00, 19.03it/s]\n","100% 1/1 [00:00<00:00, 17.55it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0010\n","\n","Predicting case_0011:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 17.52it/s]\n","100% 1/1 [00:00<00:00, 18.06it/s]\n","100% 1/1 [00:00<00:00, 18.12it/s]\n","100% 1/1 [00:00<00:00, 17.70it/s]\n","100% 1/1 [00:00<00:00, 19.37it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0011\n","\n","Predicting case_0012:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.39it/s]\n","100% 1/1 [00:00<00:00, 13.94it/s]\n","100% 1/1 [00:00<00:00, 15.74it/s]\n","100% 1/1 [00:00<00:00, 18.72it/s]\n","100% 1/1 [00:00<00:00, 18.22it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0012\n","\n","Predicting case_0013:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 19.13it/s]\n","100% 1/1 [00:00<00:00, 17.29it/s]\n","100% 1/1 [00:00<00:00, 18.63it/s]\n","100% 1/1 [00:00<00:00, 18.11it/s]\n","100% 1/1 [00:00<00:00, 18.67it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0013\n","\n","Predicting case_0014:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 19.07it/s]\n","100% 1/1 [00:00<00:00, 18.85it/s]\n","100% 1/1 [00:00<00:00, 18.94it/s]\n","100% 1/1 [00:00<00:00, 18.62it/s]\n","100% 1/1 [00:00<00:00, 19.11it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0014\n","\n","Predicting case_0015:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.31it/s]\n","100% 1/1 [00:00<00:00, 18.53it/s]\n","100% 1/1 [00:00<00:00, 19.11it/s]\n","100% 1/1 [00:00<00:00, 16.73it/s]\n","100% 1/1 [00:00<00:00, 18.47it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0015\n","\n","Predicting case_0016:\n","perform_everything_on_device: True\n","100% 1/1 [00:00<00:00, 18.28it/s]\n","100% 1/1 [00:00<00:00, 18.89it/s]\n","100% 1/1 [00:00<00:00, 18.88it/s]\n","100% 1/1 [00:00<00:00, 19.04it/s]\n","100% 1/1 [00:00<00:00, 18.57it/s]\n","sending off prediction to background worker for resampling and export\n","done with case_0016\n"]}]},{"cell_type":"code","source":["import nibabel as nib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from ipywidgets import interact, IntSlider, fixed\n","\n","def load_nii_file(file_path):\n","    nii = nib.load(file_path)\n","    return nii.get_fdata()\n","\n","def show_slices(image, ground_truth, slice_index):\n","    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","    axes[0].imshow(image[:, :, slice_index], cmap=\"gray\")\n","    axes[0].set_title(\"Image Slice\")\n","    axes[1].imshow(ground_truth[:, :, slice_index], cmap=\"gray\")\n","    axes[1].set_title(\"Ground Truth Slice\")\n","    plt.show()\n","\n","image_file = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_TrainingSplit/segmentationresults/case_0004.nii.gz'\n","ground_truth_file = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_TrainingSplit/labelsTr/case_0004.nii.gz'\n","image_data = load_nii_file(image_file)\n","ground_truth_data = load_nii_file(ground_truth_file)\n","\n","assert image_data.shape == ground_truth_data.shape, \"Image and Ground Truth dimensions do not match!\"\n","\n","max_slices = image_data.shape[2] - 1\n","interact(show_slices, image=fixed(image_data), ground_truth=fixed(ground_truth_data),\n","         slice_index=IntSlider(min=0, max=max_slices, step=1, value=0));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335,"referenced_widgets":["b9949e54c81e415f80a80c784a17feee","2889c08ac68243e58db37f77e48a4d75","234717007cb6426f8cd9527d424cc819","42dbc7c422af4939b3783acc3d07e501","4bb93d8b3236452aa4977ac0c0e3554e","e864054b545f40cba816362b45786271","7b5924eef82d42288e6c45ad20b16681"]},"id":"L9ZfzlTSwmmV","executionInfo":{"status":"ok","timestamp":1718201581065,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"fe678876-37b0-45df-dbf7-305c54582783"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=0, description='slice_index', max=4), Output()), _dom_classes=('widget-i"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9949e54c81e415f80a80c784a17feee"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","import nibabel as nib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","def load_nii_file(file_path):\n","    nii = nib.load(file_path)\n","    return nii.get_fdata()\n","\n","def normalize_image(image):\n","    return (image - np.min(image)) / (np.max(image) - np.min(image))\n","\n","def overlay_images_with_color(original, ground_truth, segmentation, alpha=0.5):\n","    normalized_original = normalize_image(original)\n","    colored_overlay_gt = np.zeros((*ground_truth.shape, 3))\n","    colored_overlay_seg = np.zeros((*segmentation.shape, 3))\n","    colored_overlay_gt[..., 2] = ground_truth\n","    colored_overlay_seg[..., 0] = segmentation\n","    combined = np.stack([normalized_original]*3, axis=-1)\n","    mask_gt = ground_truth != 0\n","    mask_seg = segmentation != 0\n","    combined[mask_gt] = combined[mask_gt] * (1 - alpha) + colored_overlay_gt[mask_gt] * alpha\n","    combined[mask_seg] = combined[mask_seg] * (1 - alpha) + colored_overlay_seg[mask_seg] * alpha\n","    overlap_mask = mask_gt & mask_seg\n","    combined[overlap_mask] = [0, 1, 0]\n","    return combined\n","\n","def save_and_visualize_overlays(original_path, ground_truth_path, segmentation_path, output_dir):\n","    original = load_nii_file(original_path)\n","    ground_truth = load_nii_file(ground_truth_path)\n","    segmentation = load_nii_file(segmentation_path)\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    num_slices = min(original.shape[2], 5)\n","    for i in range(num_slices):\n","        combined_overlay = overlay_images_with_color(original[:, :, i], ground_truth[:, :, i], segmentation[:, :, i], alpha=0.5)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n","        axes[0, 0].imshow(original[:, :, i], cmap='gray')\n","        axes[0, 0].set_title('Original Slice')\n","        axes[0, 0].axis('off')\n","        axes[0, 1].imshow(overlay_images_with_color(original[:, :, i], ground_truth[:, :, i], np.zeros_like(ground_truth[:, :, i]), alpha=0.5))\n","        axes[0, 1].set_title('Ground Truth Overlay')\n","        axes[0, 1].axis('off')\n","        axes[1, 0].imshow(overlay_images_with_color(original[:, :, i], np.zeros_like(segmentation[:, :, i]), segmentation[:, :, i], alpha=0.5))\n","        axes[1, 0].set_title('Segmentation Overlay')\n","        axes[1, 0].axis('off')\n","        axes[1, 1].imshow(combined_overlay)\n","        axes[1, 1].set_title('Combined Overlay')\n","        axes[1, 1].axis('off')\n","        blue_patch = mpatches.Patch(color='blue', label='Manual segmentation')\n","        red_patch = mpatches.Patch(color='red', label='Automated segmentation')\n","        green_patch = mpatches.Patch(color='green', label='Overlap')\n","        fig.legend(handles=[blue_patch, red_patch, green_patch], loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n","        plt.savefig(os.path.join(output_dir, f'slice_{i+1}.png'), bbox_inches='tight')\n","        plt.close(fig)\n","\n","original_dir = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/imagesTr'\n","ground_truth_dir = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/labelsTr'\n","segmentation_dir = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/Segmentation'\n","output_base_dir = '/content/drive/MyDrive/SegmentationResultsImagesPart2'\n","\n","for file_name in os.listdir(original_dir):\n","    if file_name.endswith('.nii.gz'):\n","        original_path = os.path.join(original_dir, file_name)\n","        ground_truth_path = os.path.join(ground_truth_dir, file_name.replace('_0000.nii.gz', '.nii.gz'))\n","        segmentation_path = os.path.join(segmentation_dir, file_name.replace('_0000.nii.gz', '.nii.gz'))\n","        if os.path.exists(ground_truth_path) and os.path.exists(segmentation_path):\n","            output_dir = os.path.join(output_base_dir, os.path.splitext(file_name)[0])\n","            save_and_visualize_overlays(original_path, ground_truth_path, segmentation_path, output_dir)\n","\n","print(\"Overlays saved for all files.\")\n"],"metadata":{"id":"ZimloRhSwmu2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N0pJ6t5gwm0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P0Oj1bJ-wm3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nnUNetv2_predict -i /content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/imagesTs -o /content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/Segmentation  -d 3 -c 3d_fullres -tr nnUNetTrainer_100epochs"],"metadata":{"id":"w42wNgoauEU0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718124143799,"user_tz":-330,"elapsed":12711,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"1a7f261d-ac66-4b30-fdc7-8aa46b1fbf4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_predict\", line 8, in <module>\n","    sys.exit(predict_entry_point())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/inference/predict_from_raw_data.py\", line 859, in predict_entry_point\n","    predictor.initialize_from_trained_model_folder(\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/inference/predict_from_raw_data.py\", line 84, in initialize_from_trained_model_folder\n","    checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 997, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 444, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 425, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/newData/nnUNet_results/Dataset003_TrainingSplit/nnUNetTrainer_100epochs__nnUNetPlans__3d_fullres/fold_0/checkpoint_final.pth'\n"]}]},{"cell_type":"code","source":["import nibabel as nib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from ipywidgets import interact, IntSlider, fixed\n","\n","def load_nii_file(file_path):\n","    nii = nib.load(file_path)\n","    return nii.get_fdata()\n","\n","def show_slices(image, ground_truth, slice_index):\n","    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","    axes[0].imshow(image[:, :, slice_index], cmap=\"gray\")\n","    axes[0].set_title(\"Image Slice\")\n","    axes[1].imshow(ground_truth[:, :, slice_index], cmap=\"gray\")\n","    axes[1].set_title(\"Ground Truth Slice\")\n","    plt.show()\n","\n","image_file = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset001_FCDSegmentation3D/Segmentation/case_0020.nii.gz'\n","ground_truth_file = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset001_FCDSegmentation3D/labelsTr/case_0020.nii.gz'\n","image_data = load_nii_file(image_file)\n","ground_truth_data = load_nii_file(ground_truth_file)\n","\n","assert image_data.shape == ground_truth_data.shape, \"Image and Ground Truth dimensions do not match!\"\n","\n","max_slices = image_data.shape[2] - 1\n","interact(show_slices, image=fixed(image_data), ground_truth=fixed(ground_truth_data),\n","         slice_index=IntSlider(min=0, max=max_slices, step=1, value=0));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335,"referenced_widgets":["6f4ec4c5e5514329878286e90e48710b","acaec8f3910c4b7b9163e9377c463488","2bcba24310eb4378a4b7aae3366b4e28","0f9dc8f05f654b2695194fd0fdc13d0f","bf100ba9b1d843c6bf1ce326de14492c","5259c502c54b49f285bdf9fd1182f749","97f5647110f14618a3f595ff2cb886de"]},"id":"A3tFbG1rWJ0v","executionInfo":{"status":"ok","timestamp":1718124211266,"user_tz":-330,"elapsed":4632,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"1da47b5d-5648-42c1-e2dd-1b6202b6fa5f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=0, description='slice_index', max=4), Output()), _dom_classes=('widget-i"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f4ec4c5e5514329878286e90e48710b"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","import nibabel as nib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","def load_nii_file(file_path):\n","    nii = nib.load(file_path)\n","    return nii.get_fdata()\n","\n","def normalize_image(image):\n","    return (image - np.min(image)) / (np.max(image) - np.min(image))\n","\n","def overlay_images_with_color(original, ground_truth, segmentation, alpha=0.5):\n","    normalized_original = normalize_image(original)\n","    colored_overlay_gt = np.zeros((*ground_truth.shape, 3))\n","    colored_overlay_seg = np.zeros((*segmentation.shape, 3))\n","    colored_overlay_gt[..., 2] = ground_truth\n","    colored_overlay_seg[..., 0] = segmentation\n","    combined = np.stack([normalized_original]*3, axis=-1)\n","    mask_gt = ground_truth != 0\n","    mask_seg = segmentation != 0\n","    combined[mask_gt] = combined[mask_gt] * (1 - alpha) + colored_overlay_gt[mask_gt] * alpha\n","    combined[mask_seg] = combined[mask_seg] * (1 - alpha) + colored_overlay_seg[mask_seg] * alpha\n","    overlap_mask = mask_gt & mask_seg\n","    combined[overlap_mask] = [0, 1, 0]\n","    return combined\n","\n","def save_and_visualize_overlays(original_path, ground_truth_path, segmentation_path, output_dir):\n","    original = load_nii_file(original_path)\n","    ground_truth = load_nii_file(ground_truth_path)\n","    segmentation = load_nii_file(segmentation_path)\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    num_slices = min(original.shape[2], 5)\n","    for i in range(num_slices):\n","        combined_overlay = overlay_images_with_color(original[:, :, i], ground_truth[:, :, i], segmentation[:, :, i], alpha=0.5)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n","        axes[0, 0].imshow(original[:, :, i], cmap='gray')\n","        axes[0, 0].set_title('Original Slice')\n","        axes[0, 0].axis('off')\n","        axes[0, 1].imshow(overlay_images_with_color(original[:, :, i], ground_truth[:, :, i], np.zeros_like(ground_truth[:, :, i]), alpha=0.5))\n","        axes[0, 1].set_title('Ground Truth Overlay')\n","        axes[0, 1].axis('off')\n","        axes[1, 0].imshow(overlay_images_with_color(original[:, :, i], np.zeros_like(segmentation[:, :, i]), segmentation[:, :, i], alpha=0.5))\n","        axes[1, 0].set_title('Segmentation Overlay')\n","        axes[1, 0].axis('off')\n","        axes[1, 1].imshow(combined_overlay)\n","        axes[1, 1].set_title('Combined Overlay')\n","        axes[1, 1].axis('off')\n","        blue_patch = mpatches.Patch(color='blue', label='Manual segmentation')\n","        red_patch = mpatches.Patch(color='red', label='Automated segmentation')\n","        green_patch = mpatches.Patch(color='green', label='Overlap')\n","        fig.legend(handles=[blue_patch, red_patch, green_patch], loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n","        plt.savefig(os.path.join(output_dir, f'slice_{i+1}.png'), bbox_inches='tight')\n","        plt.close(fig)\n","\n","original_dir = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/imagesTr'\n","ground_truth_dir = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/labelsTr'\n","segmentation_dir = '/content/drive/MyDrive/newData/nnUNet_raw/Dataset003_FCDSegmentation3D/Segmentation'\n","output_base_dir = '/content/drive/MyDrive/SegmentationResultsImagesPart2'\n","\n","for file_name in os.listdir(original_dir):\n","    if file_name.endswith('.nii.gz'):\n","        original_path = os.path.join(original_dir, file_name)\n","        ground_truth_path = os.path.join(ground_truth_dir, file_name.replace('_0000.nii.gz', '.nii.gz'))\n","        segmentation_path = os.path.join(segmentation_dir, file_name.replace('_0000.nii.gz', '.nii.gz'))\n","        if os.path.exists(ground_truth_path) and os.path.exists(segmentation_path):\n","            output_dir = os.path.join(output_base_dir, os.path.splitext(file_name)[0])\n","            save_and_visualize_overlays(original_path, ground_truth_path, segmentation_path, output_dir)\n","\n","print(\"Overlays saved for all files.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbHnsoeW8Nu9","executionInfo":{"status":"ok","timestamp":1718072173727,"user_tz":-330,"elapsed":413699,"user":{"displayName":"Shubham Joshi","userId":"13971836439059875510"}},"outputId":"376092e5-a75b-4dbd-d26b-88c84c09699b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overlays saved for all files.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oMzYkNzSLy_h"},"execution_count":null,"outputs":[]}]}